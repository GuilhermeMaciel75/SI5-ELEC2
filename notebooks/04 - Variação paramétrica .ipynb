{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fase 4 - Variação paramétrica**\n",
    "\n",
    "**Alunos:**\n",
    "\n",
    "Erlan Lira Soares Junior - elsj\n",
    "\n",
    "Felipe de Barros Moraes - fbm3\n",
    "\n",
    "Guilherme Maciel de Melo - gmm7\n",
    "\n",
    "Rubens Nascimento de Lima - rnl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas Externas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "# Bibliotecas Locais\n",
    "os.chdir(\"..\")\n",
    "from lib import plots, runner, util\n",
    "\n",
    "# Definido Variáveis globais e ignorando Warninig\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 51\n",
    "GPU_AVALIABLE = torch.cuda.is_available()\n",
    "\n",
    "# Conjunto de treino\n",
    "X_train = pd.read_csv('./data/processed/X_train.csv')\n",
    "Y_train = pd.read_csv('./data/processed/Y_train.csv')\n",
    "\n",
    "Y_train['class'] = Y_train['class'].apply(lambda val: 1 if val == 'UP' else 0)\n",
    "\n",
    "# Conjunto de validação\n",
    "X_val = pd.read_csv('./data/processed/X_val.csv')\n",
    "Y_val = pd.read_csv('./data/processed/Y_val.csv')\n",
    "\n",
    "\n",
    "Y_val['class'] = Y_val['class'].apply(lambda val: 1 if val == 'UP' else 0)\n",
    "\n",
    "# Conjunto de teste\n",
    "X_test = pd.read_csv('./data/processed/X_test.csv')\n",
    "Y_test = pd.read_csv('./data/processed/Y_test.csv')\n",
    "\n",
    "Y_test['class'] = Y_test['class'].apply(lambda val: 1 if val == 'UP' else 0)\n",
    "\n",
    "dataset = [X_train, Y_train, X_val, Y_val, X_test, Y_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Técnica de Modelagem\n",
    "\n",
    "Para essa etapa do CRISP-DM, utilizaremos o dataset base gerado na fase 3, e os modelos selecionados na fase 1 junto ao stakeholder. Durante a fase de modelagem, utilizaremos os seguintes modelos:\n",
    "\n",
    "- K-NN (K-Nearest Neighbors)\n",
    "- LVQ (Learning Vector Quantization):\n",
    "- Árvore de Decisão:\n",
    "- SVM (Support Vector Machine)\n",
    "- Random Forest\n",
    "- Rede Neural MLP (Multilayer Perceptron)\n",
    "- Comitê de Redes Neurais Artificiais\n",
    "- Comitê Heterogêneo (Stacking)\n",
    "- XGBoost\n",
    "- LightGBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Suposições da Modelagem\n",
    "\n",
    "Modelos como o **K-NN (K-Nearest Neighbors)**, por exemplo, podem sofrer com a deriva de conceito devido à sua dependência das instâncias mais próximas no espaço de características. Como o K-NN não leva em consideração o histórico das mudanças nos dados, ele pode ter dificuldades em se adaptar quando a distribuição de consumo de energia muda ao longo do tempo, especialmente em casos atípicos na variação do consumo e gasto energético, resultando em uma performance instável. Dessa forma, o desempenho desse modelo será muito dependente da escolha do valor de K e, ainda assim, não acreditamos que esse modelo terá o melhor desempenho em comparação com outras possibilidades devido a sua simplicidade.\n",
    "\n",
    "Já o **LVQ (Learning Vector Quantization)**, um modelo de rede neural supervisionada, pode ser uma boa escolha para lidar com a separação em clusters, pois é projetado para identificar regiões de decisão e realizar classificações baseadas nessas regiões. No entanto, assim como o K-NN, o LVQ pode ser sensível à deriva de conceito e a casos atípicos (outliers), especialmente se as mudanças nos dados forem substanciais. Apesar disso, devido à dificuldade em encontrar bibliotecas que implementem esse modelo, e à necessidade de utilizar o algoritmo visto em sala, que não é muito eficiente no treinamento, acreditamos que ele também não apresentará resultados satisfatórios, devido ao alto tempo de treinamento e ao baixo desempenho nos testes iniciais.\n",
    "\n",
    "A **Árvore de Decisão**, por sua vez, é mais resistente à deriva do que os modelos baseados em vizinhos, pois realiza divisões hierárquicas nos dados com base nas variáveis mais relevantes, se preocupando em encontrar valores que realizem divisões entre as classes. Como não há uma mudança significativa na distribuição de dados do modelo, acreditamos que ela poderá ter um desempenho aceitável. Entretanto, a falta de robustez do modelo e a complexidade do problema podem dificultar a predição da classe alvo. Por fim, outro problema que ela pode enfrentar é o **overfitting**, capturando ruídos em vez de padrões generalizáveis.\n",
    "\n",
    "No caso do **SVM (Support Vector Machine)**, o modelo é eficaz na criação de margens de separação, principalmente em problemas de classificação não linear. Contudo, a sua eficácia no ELEC2 pode ser afetada pela necessidade de ajuste do kernel e pela regularização. Assim a SVM pode ser muito eficaz para capturar padrões de consumo de energia em períodos de estabilidade, mas à medida que o mercado muda e a distribuição dos dados varia, a precisão do modelo pode ser comprometida, exigindo atualizações constantes. Ainda assim, não acreditamos que ela terá um bom desempenho para o conjunto de dados, dependendo bastante da busca de hiperpârametros.\n",
    "\n",
    "O **Random Forest**, por ser um modelo ensemble baseado em múltiplas árvores de decisão, tem a vantagem de ser mais robusto em relação à deriva de conceito, logo provavelmente deverá apresentar um resultado melhor que ele. Ao combinar previsões de várias árvores, ele é menos propenso a se ajustar excessivamente a padrões temporários ou ruidosos, o que o torna uma boa escolha para lidar com a variabilidade e com mudanças no comportamento de consumo de energia. Ainda assim, sua capacidade de **generalização** é amplamente estudada e utilizada na literatura, e o ajuste adequado dos hiperparâmetros pode proporcionar um bom equilíbrio entre complexidade e precisão. Acreditamos que o Random Forest será um modelo que irá desempenhar muito bem nas métricas de avaliação e deverá ser um dos modelos avaliados na escolha final, uma vez que foi um modelo que apresentou resultados bastante satisfatórios em artigos que utilizam essa base\n",
    "\n",
    "Modelos mais complexos, como a **Rede Neural MLP (Multilayer Perceptron)**, podem oferecer uma boa capacidade de modelar relações não lineares complexas entre as variáveis do dataset. No entanto, as redes neurais podem ser sensíveis a deriva, especialmente se não forem treinadas de forma contínua. Ainda assim, elas podem se tornar desatualizadas ao longo do tempo, caso não sejam ajustadas para capturar novas mudanças nos dados. Por fim, acreditamos que o MLP apresentará um alto desempenho, porém esse alto desempenho trará um alto **tempo de treinamento** e um alto custo de busca de hiperparâmetros.\n",
    "\n",
    "O **Comitê de Redes Neurais Artificiais**, que combina várias redes neurais para melhorar a robustez e a precisão, pode ser uma solução eficaz para enfrentar a deriva de conceito. Ao combinar diferentes redes, o comitê pode se beneficiar da diversidade de aprendizado, resultando em uma maior precisão, especialmente se combinado com técnicas de bagging ou boosting. Contudo, maximiza ainda mais o problema apresentado em MLP, uma vez que com o uso de mais de um algoritmo de MLP trará um alto custo para encontrar a melhor combinação entre essas redes neurais, além de trazer um custo computacional maior, uma vez que será necessário executar mais de um modelo desse ao mesmo tempo durante as previsões \n",
    "\n",
    "O **Comitê Heterogêneo (Stacking)**, por combinar modelos de diferentes tipos, oferece uma abordagem poderosa para lidar com dados que apresentam variabilidade temporal, como no caso do ELEC2. Ao usar uma combinação de modelos como SVM, Árvores de Decisão e Redes Neurais, o stacking pode melhorar a precisão ao capturar diferentes aspectos dos dados e suas interações, além de ser capaz de se adaptar às mudanças ao longo do tempo. Ainda assim, esse desempenho só será possível se utilizarmos bons modelos como base para esse comitê, como iremos utilizar modelos mais simples, não sabemos ao certo como será o desempenho dessa estratégia. Por fim, devido a esse desafio de modelagem do comitê e a necessidade de utilizar mais de um modelo ao mesmo tempo, acreditamos que ele irá possuir um bom desempenho, mas não tão eficiente frente a outras estratégias como Random Forest e XGboost.\n",
    "\n",
    "O **XGBoost** e o **LightGBM**, ambos baseados em técnicas de boosting, são modelos altamente eficazes para tarefas de classificação e regressão. O XGBoost, em particular, é um dos modelos mais populares e robustos para problemas complexos e altamente utilizado na literatura, como o ELEC2. Ele lida bem com dados desbalanceados, além de ser menos sensível a overfitting quando configurado corretamente. O LightGBM, por ser mais eficiente em termos de memória e tempo de treinamento, também é uma excelente escolha para datasets grandes e com variabilidade. Assim, ambos os modelos são robustos à deriva de conceito e podem ser ajustados facilmente para se adaptarem às mudanças nos dados de consumo de energia. Por fim, acreditamos que esses modelos apresentaram um alto desempenho e com certeza estarão na ponderação do modelo final.\n",
    "\n",
    "Dentre as opções analisadas, o **Random Forest** e o **XGBoost** se destacam como as escolhas mais promissoras para o conjunto de dados do ELEC2, considerando sua robustez à deriva de conceito, sua capacidade de lidar com a variabilidade dos dados e a facilidade de ajustes para otimizar o desempenho. A escolha final dependerá da complexidade e do equilíbrio desejado entre desempenho e custo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Design de Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Design de Execução dos Testes\n",
    "\n",
    "Nesta etapa, implementamos uma bancada de testes padronizada que será utilizada em todos os modelos para garantir que os testes sejam realizados de forma isonômica. Isso assegura que as condições de execução dos modelos sejam consistentes, permitindo comparações justas entre os diferentes modelos e hiperparâmetros.\n",
    "\n",
    "A estrutura do teste é gerida por uma função que recebe como parâmetros o modelo a ser avaliado, o conjunto de hiperparâmetros a serem investigados, e o conjunto de dados de treinamento, validação e teste. Esses parâmetros são usados para alimentar um **RandomizedSearchCV**, uma ferramenta da biblioteca scikit-learn que realiza a busca de hiperparâmetros de forma eficiente. O **RandomizedSearchCV** é particularmente útil quando há uma grande quantidade de possíveis combinações de hiperparâmetros, pois permite testar diferentes combinações de forma aleatória e rápida, sem a necessidade de uma busca exaustiva.\n",
    "\n",
    "Realizamos a execução do **RandomizedSearchCV** com 20 iterações, e em cada iteração, 20 combinações de parâmetros são selecionadas aleatoriamente. Esta abordagem permite uma avaliação mais diversa e uma exploração mais ampla do espaço de hiperparâmetros.\n",
    "\n",
    "Para assegurar que a combinação de hiperparâmetros gerada seja confiável, robusta e tenha boa capacidade de generalização, utilizamos a validação cruzada **K-fold** com $k = 5$. Isso significa que os dados de treinamento são divididos em 5 subconjuntos, e o modelo é treinado e validado em cada uma dessas divisões. Com isso, obtemos um total de 100 ajustes por iteração, o que resulta em 2.000 ajustes ao final de todas as iterações para um único modelo.\n",
    "\n",
    "Para a seleção do melhor modelo dentro do **RandomizedSearchCV**, utilizamos como critério principal a métrica **roc_auc**. Sua escolha se dá por sua robustez em avaliar o desempenho de classificadores, especialmente quando lidamos com classes desbalanceadas (Embora estejamos trabalhando em um problema em que as classes estão relativamente balanceadas). Essa métrica considera tanto a taxa de verdadeiros positivos quanto a taxa de falsos positivos, fornecendo uma avaliação completa da capacidade de discriminação do modelo.\n",
    "\n",
    "Após a execução do **RandomizedSearchCV**, o melhor modelo é selecionado, e realizamos testes adicionais para avaliar sua acurácia nos dados de treinamento, validação e teste. As métricas avaliadas incluem **acurácia**, **auc**, **f1_score**, **recall**, **true positive rate**, **false positive rate**, além do tempo de ajuste do modelo. Também realizamos uma análise detalhada do desempenho dos 20 melhores modelos obtidos, avaliando seu desempenho médio durante a validação cruzada. Essa análise nos permite entender melhor quais parâmetros representam o modelo de forma mais eficaz e quais estratégias podem ser adotadas para otimizar o desempenho geral.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Design da Avaliação dos Parâmetros\n",
    "\n",
    "Como discutido anteriormente, o modelo selecionado como o melhor é aquele que apresenta o maior **roc_auc** durante o processo de busca de hiperparâmetros. No entanto, para garantir uma avaliação mais completa e robusta dos parâmetros, testamos diversos outros parâmetros e utilizando uma série de plots para analisar o comportamento do modelo sob diferentes perspectivas.\n",
    "\n",
    "### 2.2.1 Curva ROC do Melhor Parâmetro x Médias do Modelo\n",
    "\n",
    "Este gráfico tem como objetivo não apenas avaliar a confiabilidade do modelo (analisando a curva ROC), mas também verificar sua estabilidade. A curva ROC do melhor modelo selecionado é comparada com a média das curvas ROC dos 20 melhores modelos. Isso nos permite identificar se o modelo selecionado apresenta um desempenho significativamente superior e estável, ou se a variação entre os modelos é excessiva, o que poderia indicar problemas de overfitting ou instabilidade.\n",
    "\n",
    "### 2.2.2 Matriz de Confusão do Melhor Estimador do Modelo\n",
    "\n",
    "A matriz de confusão oferece uma visão detalhada do desempenho do modelo ao classificar os dados em diferentes categorias. Esta análise permite avaliar a quantidade de verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos, sendo essencial para compreender os erros cometidos pelo modelo. Com ela, conseguimos analisar se o modelo tende a favorecer certas classes ou se está cometendo erros sistemáticos.\n",
    "\n",
    "### 2.2.3 Comparação das Métricas Médias x Máximo\n",
    "\n",
    "Este gráfico compara a **média das métricas** de cada modelo com o **valor máximo alcançado por algum modelo em cada métrica**. A ideia aqui é avaliar o quão distante a média dos modelos fica do valor máximo observado em cada métrica. Isso permite verificar se existe uma grande variação entre os modelos, ou se muitos modelos apresentam um desempenho similar, com o valor máximo representando o melhor resultado possível dentro daquele conjunto de parâmetros. Esse gráfico ajuda a entender a distribuição dos desempenhos e a consistência dos modelos, destacando quais métricas têm uma maior dispersão e quais apresentam maior estabilidade nos resultados.\n",
    "\n",
    "### 2.2.4 Comparação das Métricas para Cada Estimador\n",
    "\n",
    "Este gráfico apresenta as métricas de desempenho de cada estimador, representadas ao longo do eixo X, com valores de desempenho no eixo Y. As linhas representam diferentes métricas de avaliação como **acurácia**, **f1_score**, **recall**, e **auc**, e são agrupadas para os dados de treinamento, validação e teste. A análise desse gráfico permite avaliar como as métricas variam entre os diferentes parâmetros selecionados e suas iterações, facilitando a comparação entre eles e a escolha do melhor conjunto de parâmetros.\n",
    "\n",
    "### 2.2.5 Comparação do Melhor Estimador Durante a Cross Validation\n",
    "\n",
    "Neste gráfico, apresentamos os valores dos scores **roc_auc** obtidos durante a execução da validação cruzada. Esse gráfico oferece uma visão de como o modelo de melhor desempenho se comporta ao longo das divisões dos dados de treinamento e teste, permitindo avaliar a consistência do modelo e seu desempenho em diferentes subconjuntos dos dados.\n",
    "\n",
    "### 2.2.6 Comparação do Desempenho Médio dos Melhores Estimadores Durante a Cross Validation\n",
    "\n",
    "Esse gráfico mostra o **desempenho médio** dos melhores estimadores ao longo das divisões da validação cruzada. Ele é fundamental para entender a consistência do desempenho dos modelos, fornecendo uma visão global de como os modelos se comportam em diferentes cenários, o que pode ajudar na seleção do modelo com maior capacidade de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construção dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Modelos\n",
    "\n",
    "- K-NN\n",
    "- LVQ (Learning Vector Quantization)\n",
    "- Árvore de Decisão\n",
    "- SVM (Support Vector Machine)\n",
    "- Random Forest\n",
    "- Rede Neural MLP (Multilayer Perceptron)\n",
    "- Comitê de Redes Neurais Artificiais\n",
    "- Comitê Heterogêneo (Stacking)\n",
    "- XGBoost\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Descrição dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. K-NN\n",
    "\n",
    "O K-NN é um algoritmo de aprendizado supervisionado simples e intuitivo. Ele classifica um novo ponto de dados com base na classe dos seus \"K\" vizinhos mais próximos no espaço de características. A classe mais comum entre esses vizinhos é atribuída ao novo ponto. Ainda assim, é considerado um algoritmo \"preguiçoso\", pois não aprende um modelo explícito, mas armazena os dados de treinamento e realiza a classificação apenas quando necessário, não havendo um treinamento propriamente dito, apenas uma comparação entre os dados de treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. LVQ (Learning Vector Quantization)\n",
    "\n",
    "O LVQ é um algoritmo de aprendizado supervisionado que cria um conjunto de vetores de código (protótipos) que representam as diferentes classes nos dados. Assim, durante o treinamento, esses vetores de código são ajustados para se aproximarem dos pontos de dados da mesma classe e se afastarem dos pontos de dados de classes diferentes, gerando separações no espaço vetorial. Desse modo, na classificação, o novo ponto de dados é atribuído à classe do vetor de código mais próximo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from random import randrange\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_array\n",
    "\n",
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = np.sum((row1[:-1] - row2[:-1])**2)\n",
    "    return sqrt(distance)\n",
    "\n",
    "# Locate the best matching unit\n",
    "def get_best_matching_unit(codebooks, test_row):\n",
    "    distances = np.array([euclidean_distance(codebook, test_row) for codebook in codebooks])\n",
    "    return codebooks[np.argmin(distances)]\n",
    "\n",
    "# Make a prediction with codebook vectors\n",
    "def predict(codebooks, test_row):\n",
    "    bmu = get_best_matching_unit(codebooks, test_row)\n",
    "    return bmu[-1]\n",
    "\n",
    "# Create a random codebook vector\n",
    "def random_codebook(train):\n",
    "    n_records = len(train)\n",
    "    n_features = train.shape[1]\n",
    "    codebook = train[randrange(n_records), :]\n",
    "    return codebook\n",
    "\n",
    "# Train a set of codebook vectors\n",
    "def train_codebooks(train, n_codebooks, lrate, epochs):\n",
    "    codebooks = np.array([random_codebook(train) for _ in range(n_codebooks)])\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        for row in train:\n",
    "            bmu = get_best_matching_unit(codebooks, row)\n",
    "            for i in range(len(row) - 1):\n",
    "                error = row[i] - bmu[i]\n",
    "                if bmu[-1] == row[-1]:\n",
    "                    bmu[i] += rate * error\n",
    "                else:\n",
    "                    bmu[i] -= rate * error\n",
    "    return codebooks\n",
    "\n",
    "# LVQ Algorithm as a custom classifier\n",
    "class LVQClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_codebooks=10, lrate=0.1, epochs=100):\n",
    "        self.n_codebooks = n_codebooks\n",
    "        self.lrate = lrate\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Validate the input arrays\n",
    "        X = check_array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Combine features and labels\n",
    "        train = np.column_stack((X, y))\n",
    "        self.codebooks_ = train_codebooks(train, self.n_codebooks, self.lrate, self.epochs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = check_array(X)\n",
    "        predictions = np.array([predict(self.codebooks_, row) for row in X])\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = check_array(X)\n",
    "        probabilities = []\n",
    "        for row in X:\n",
    "            bmu = get_best_matching_unit(self.codebooks_, row)\n",
    "            class_label = bmu[-1]\n",
    "            # For simplicity, we will return a binary classification probability for each class\n",
    "            prob = np.array([0.0, 0.0])  # Assuming binary classification\n",
    "            prob[class_label] = 1.0  # Fully confident in the class of the BMU\n",
    "            probabilities.append(prob)\n",
    "        return np.array(probabilities)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X = check_array(X)\n",
    "        # This function will return the distances to the codebooks, which can be used for decision making\n",
    "        distances = np.array([euclidean_distance(get_best_matching_unit(self.codebooks_, row), row) for row in X])\n",
    "        return distances\n",
    "\n",
    "\n",
    "lvq_model = LVQClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Árvore de Decisão\n",
    "\n",
    "As árvores de decisão é um dos modelos mais simples de aprendizado supervisionado que particionam o espaço de características em regiões retangulares, cada uma associada a uma classe. Desse modo a árvore é construída por meio de uma série de divisões binárias, onde cada nó interno representa um teste em uma característica e cada folha representa uma classe. A classificação de um novo ponto de dados é feita percorrendo a árvore, seguindo os ramos apropriados com base nos valores das características.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. SVM (Support Vector Machine)\n",
    "\n",
    "O SVM é um algoritmo de aprendizado supervisionado que busca encontrar o hiperplano que melhor separa as diferentes classes nos dados. Assim, o hiperplano ideal é aquele que maximiza a margem entre as classes, ou seja, a distância entre o hiperplano e os pontos de dados mais próximos de cada classe (vetores de suporte). A partir dessas características, o  SVM pode lidar com dados linearmente separáveis e não linearmente separáveis, utilizando o truque do kernel para mapear os dados em um espaço de maior dimensão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(\n",
    "    probability=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5. Random Forest\n",
    "\n",
    "O Random Forest é um algoritmo de aprendizado supervisionado que combina várias árvores de decisão para melhorar a precisão e reduzir o overfitting. Ele é um algoritmo com um desempenho baste alto em problemas de classificação em dados tabulares. Sendo assim, cada árvore é treinada em um subconjunto aleatório dos dados e em um subconjunto aleatório das características. Desse modo, a classificação de um novo ponto de dados é feita por meio de votação majoritária entre as árvores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6. Rede Neural MLP (Multilayer Perceptron)\n",
    "\n",
    "O MLP é um tipo de rede neural artificial que consiste em várias camadas de neurônios interconectados, podemos adicionar novas camadas, bem como setar diferentes números de neurônios para cada uma dessas camadas. Desse modo, cada neurônio aplica uma função de ativação a uma soma ponderada de suas entradas. Assim, o MLP pode aprender relações complexas entre as características e as classes, ajustando os pesos das conexões durante o treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model = MLPClassifier(\n",
    "    max_iter=500,\n",
    "    random_state=RANDOM_STATE,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7. Comitê de Redes Neurais Artificiais\n",
    "\n",
    "Um comitê de redes neurais artificiais combina as previsões de várias redes neurais individuais para melhorar a precisão e a robustez. Portanto, as redes neurais podem ser treinadas com diferentes inicializações, arquiteturas ou subconjuntos dos dados. Assim, a classificação de um novo ponto de dados é feita por meio de votação majoritária ou média das previsões das redes neurais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.8. Comitê Heterogêneo (Stacking)\n",
    "\n",
    "O Stacking é uma técnica de aprendizado de comitê que combina as previsões de vários modelos diferentes (heterogêneos) para melhorar a precisão. Um modelo de \"meta-aprendizagem\" é treinado para combinar as previsões dos modelos base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.9. XGBoost\n",
    "\n",
    "O XGBoost (Extreme Gradient Boosting) é um algoritmo de aprendizado de máquina baseado em árvores de decisão que utiliza técnicas de boosting para melhorar a precisão, bastante querido pela literatura devido ao seu alto desempenho para diferentes bases de dados. O boosting é um método iterativo que treina modelos sequencialmente, onde cada modelo tenta corrigir os erros dos modelos anteriores, ou seja, acabamos criando uma árvore desses modelos que tentam corrigir o erro do anterior. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.10. LightGBM\n",
    "\n",
    "O LightGBM (Light Gradient Boosting Machine) é outro algoritmo de aprendizado de máquina baseado em árvores de decisão que utiliza técnicas de boosting. O LightGBM é projetado para ser mais rápido e eficiente do que o XGBoost, especialmente em conjuntos de dados grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions_lvq = {\n",
    "    'n_codebooks': [5, 10, 30, 50, 100],\n",
    "    'lrate': [0.01, 0.05, 0.1, 0.5],\n",
    "    'epochs': [2, 20, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.1, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a9e0e8591440328e2a7f8a4ff30020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Realizando a Busca de Parâmetros por 20 iterações:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_lvq, model_lvq, cv_lvq, loss, all_cv_lvg \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_paramsv2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlvq_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_distributions_lvq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlvq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame((result_lvq\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m      6\u001b[0m df\n",
      "File \u001b[1;32mc:\\Users\\rubenslima\\Desktop\\Faculdade\\SI5-ELEC2\\lib\\runner.py:144\u001b[0m, in \u001b[0;36msearch_paramsv2\u001b[1;34m(model, params, model_name, dataset, n_iter, score, verbose, save)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRealizando a Busca de Parâmetros por 20 iterações\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    131\u001b[0m     search_model \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m    132\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    133\u001b[0m         param_distributions\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[0;32m    142\u001b[0m     )\n\u001b[1;32m--> 144\u001b[0m     \u001b[43msearch_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     all_cv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_cv, pd\u001b[38;5;241m.\u001b[39mDataFrame(search_model\u001b[38;5;241m.\u001b[39mcv_results_)\u001b[38;5;241m.\u001b[39miloc[search_model\u001b[38;5;241m.\u001b[39mbest_index_]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    148\u001b[0m     Y_pred_train \u001b[38;5;241m=\u001b[39m search_model\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "result_lvq, model_lvq, cv_lvq, loss, all_cv_lvg = runner.search_paramsv2(\n",
    "    lvq_model, param_distributions_lvq, 'lvq',dataset\n",
    ")\n",
    "\n",
    "df=pd.DataFrame((result_lvq.values()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svm, model_svm, cv_svm, loss, all_cv_svm = runner.search_paramsv2(\n",
    "    svm_model,param_distributions_svm,'svm',dataset\n",
    ")\n",
    "\n",
    "df=pd.DataFrame((result_svm.values()))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
